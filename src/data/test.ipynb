{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "character_metadata_path = \"../../data/character.metadata.tsv\"\n",
    "movie_metadata_path = \"../../data/movie.metadata.tsv\"\n",
    "name_cluster_path = \"../../data/name.clusters.tsv\"\n",
    "plot_summaries_path = \"../../data/plot_summaries.tsv\"\n",
    "tvtropes_path = \"../../data/tvtropes.clusters.tsv\"\n",
    "\n",
    "\n",
    "characterMetadata = pd.read_csv(character_metadata_path, sep=\"\\t\")\n",
    "movieMetadata = pd.read_csv(movie_metadata_path, sep=\"\\t\")\n",
    "nameCluster = pd.read_csv(\n",
    "    name_cluster_path,\n",
    "    sep=\"\\t\",\n",
    "    names=[\"Character name\", \"Freebase character/actor map ID\"],\n",
    ")\n",
    "plotSummaries = pd.read_csv(\n",
    "    plot_summaries_path, sep=\"\\t\", names=[\"Wikipedia movie ID\", \"plot\"]\n",
    ")\n",
    "tvtropes = pd.read_csv(tvtropes_path, sep=\"\\t\", names=[\"trope\", \"details\"])\n",
    "tvtropes = pd.concat(\n",
    "    [tvtropes[\"trope\"], tvtropes[\"details\"].apply(json.loads).apply(pd.Series)], axis=1\n",
    ")\n",
    "tvtropes = tvtropes.rename(columns={\"id\": \"Freebase character/actor map ID\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Character Metadata\")\n",
    "display(characterMetadata.head())\n",
    "print(\"Movie Metadata\")\n",
    "display(movieMetadata.head())\n",
    "print(\"Name Cluster\")\n",
    "display(nameCluster.head())\n",
    "print(\"Plot Summaries\")\n",
    "display(plotSummaries.head())\n",
    "print(\"TV Tropes\")\n",
    "display(tvtropes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.merge(\n",
    "    movieMetadata,\n",
    "    characterMetadata,\n",
    "    on=[\"Wikipedia movie ID\", \"Freebase movie ID\"],\n",
    "    how=\"inner\",\n",
    ")\n",
    "movies = pd.merge(movies, plotSummaries, on=\"Wikipedia movie ID\", how=\"inner\")\n",
    "# merge with tvtropes\n",
    "# movies = pd.merge(movies, tvtropes, on=\"Freebase character/actor map ID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20k movies don't have any characters\n",
    "\n",
    "We will not merge name clusters because there is a baseline bias - we would only consider movies that have been successful and have sequels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movies), len(movieMetadata), len(movies.groupby(\"Wikipedia movie ID\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0 top terms:\n",
      "characters, follows, man, director, set, young, movie, life, story, film\n",
      "\n",
      "Cluster 1 top terms:\n",
      "daughter, girl, story, marry, married, life, marriage, falls, falls love, love\n",
      "\n",
      "Cluster 2 top terms:\n",
      "later, home, finds, goes, money, man, car, tells, house, police\n",
      "\n",
      "Cluster 3 top terms:\n",
      "crew, soldiers, world, men, captain, king, army, earth, ship, war\n",
      "\n",
      "Cluster 4 top terms:\n",
      "father, love, school, new, tells, elizabeth, john, mother, peter, mary\n",
      "\n",
      "Cluster 5 top terms:\n",
      "time, wife, love, man, life, home, tells, family, susan, david\n",
      "\n",
      "Cluster 6 top terms:\n",
      "time, friends, town, wife, jack, school, young, man, life, new\n",
      "\n",
      "Cluster 7 top terms:\n",
      "son, george, tells, house, home, ring, father, family, new, sam\n",
      "\n",
      "Cluster 8 top terms:\n",
      "husband, home, kids, child, mother, house, parents, wife, family, children\n",
      "\n",
      "Cluster 9 top terms:\n",
      "brother, old, house, home, life, daughter, son, mother, family, father\n"
     ]
    }
   ],
   "source": [
    "# Add these imports\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Preprocess and vectorize the plot text\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=1000,  # Limit to top 1000 terms\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 2),  # Consider both single words and bigrams\n",
    "    min_df=5,  # Ignore terms that appear in less than 5 documents\n",
    ")\n",
    "\n",
    "# Create document-term matrix\n",
    "plot_features = tfidf.fit_transform(movies[\"plot\"])\n",
    "\n",
    "# Reduce dimensionality (optional but recommended for better clustering)\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "plot_features_reduced = svd.fit_transform(plot_features)\n",
    "\n",
    "# Cluster the movies\n",
    "n_clusters = 10  # You can adjust this number\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "movies[\"cluster\"] = kmeans.fit_predict(plot_features_reduced)\n",
    "\n",
    "\n",
    "# Analyze the clusters\n",
    "def get_top_terms_per_cluster():\n",
    "    # Get the cluster centers in terms of the original TF-IDF features\n",
    "    original_space_centroids = svd.inverse_transform(kmeans.cluster_centers_)\n",
    "\n",
    "    for cluster in range(n_clusters):\n",
    "        top_indices = np.argsort(original_space_centroids[cluster])[\n",
    "            -10:\n",
    "        ]  # Top 10 terms\n",
    "        top_terms = [tfidf.get_feature_names_out()[i] for i in top_indices]\n",
    "        print(f\"\\nCluster {cluster} top terms:\")\n",
    "        print(\", \".join(top_terms))\n",
    "\n",
    "\n",
    "# Display results\n",
    "get_top_terms_per_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
